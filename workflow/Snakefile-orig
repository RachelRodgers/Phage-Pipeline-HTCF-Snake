"""
Snakefile for running phage assembly from Hecatomb QC'd reads.

Rachel Rodgers, June 2021
"""

import os
import sys

#----- Snakemake Set Up -----#

configfile: "./config/phage_pipeline_config.yaml"

# Paths

HECATOMB_DIR = config["Paths"]["Hecatomb"]

# Write out the CT2 template path and environment path:

SCRIPTS = os.path.join("workflow", "scripts")

if not os.path.exists(SCRIPTS):
	os.makedirs(SCRIPTS)

ct2Template = open(os.path.join(SCRIPTS, "ct2Temp.txt"), "w")
CT2_TEMPLATE = config["Paths"]["CT2_template"]
ct2Template.write(CT2_TEMPLATE)
ct2Template.close()

ct2Env = open(os.path.join(SCRIPTS, "ct2Env.txt"), "w")
CT2_ENV = config["Paths"]["CT2_path"]
ct2Env.write(CT2_ENV)
ct2Env.close()

# Tools

BBTOOLS = config["Tools"]["BBTools"]
MEGAHIT = config["Tools"]["megahit"]
SEQKIT = config["Tools"]["SeqKit"]
FLYE = config["Tools"]["flye"]
R = config["Tools"]["R"]
METASPADES = config["Tools"]["metaSPAdes"]
BLAST = config["Tools"]["blast"]

# Databases
GVD = config["DBs"]["GVD"]
GPD = config["DBs"]["GPD"]

#----- Collect the Input Files -----#

# Pull sample names from the Hecatomb step 7 QC'd files and store in list
SAMPLES, = glob_wildcards(os.path.join(HECATOMB_DIR, "results", "QC", "step_7", "{sample}_R1.s7.out.fastq"))

#----- Rules -----#

rule all:
	input:
		os.path.join("results", "GPD_blastN_results", "GPD_contig_dictionary_blastN_results.tab"),
		os.path.join("results", "GVD_blastN_results", "GVD_contig_dictionary_blastN_results.tab"),
		os.path.join("results", "ref", "genome", "2", "summary.txt"),
		os.path.join("results", "contig_abundance_table", "contig_abundance_table.txt")
		#os.path.join("results", "ct2_annotated_contig_dictionary", "ct2_annotated_contig_dictionary_CONTIG_SUMMARY.tsv"),
		#expand(os.path.join("results", "quantification", "{sample}.rpkm"), sample = SAMPLES)

rule get_r2_singletons:
	"""
	Split R2 singletons
	"""
	input:
		os.path.join(HECATOMB_DIR, "results", "QC", "step_7", "{sample}_singletons.s7.out.fastq")
	output:
		os.path.join(HECATOMB_DIR, "results", "QC", "step_7", "{sample}_singletons_R2.out.fastq")
	shell:
		"""
		grep -A 3 '2:N:' {input} | sed '/^--$/d' > {output}
		"""

rule bbnorm:
	"""
	Digital normalization with BBNorm
	"""
	input:
		r1 = os.path.join(HECATOMB_DIR, "results", "QC", "step_7", "{sample}_R1.s7.out.fastq"),
		r2 = os.path.join(HECATOMB_DIR, "results", "QC", "step_7", "{sample}_R2.s7.out.fastq"),
		r1Singletons = os.path.join(HECATOMB_DIR, "results", "QC", "step_7", "{sample}_singletons_R1.out.fastq"),
		r2Singletons = os.path.join(HECATOMB_DIR, "results", "QC", "step_7", "{sample}_singletons_R2.out.fastq")
	output:
		r1 = os.path.join("results", "bbnorm", "{sample}_R1.norm.out.fastq"),
		r2 = os.path.join("results", "bbnorm", "{sample}_R2.norm.out.fastq")
	threads: 4
	shell:
		"""
		ml {BBTOOLS}
		bbnorm.sh \
			in={input.r1} \
			in2={input.r2} \
			extra={input.r1Singletons},{input.r2Singletons} \
			out={output.r1} \
			out2={output.r2} \
			target=20 \
			mindepth=2 \
			t={threads}
		"""

rule metaspades:
	"""
	Contig assembly per sample with metaSPAdes
	"""
	input:
		r1 = os.path.join("results", "bbnorm", "{sample}_R1.norm.out.fastq"),
		r2 = os.path.join("results", "bbnorm", "{sample}_R2.norm.out.fastq")
	params:
		directory(os.path.join("results", "metaSPAdes", "{sample}"))
	output:
		os.path.join("results", "metaSPAdes", "{sample}", "contigs.fasta")
	shell:
		"""
		{METASPADES} \
			-1 {input.r1} \
			-2 {input.r2} \
			-o {params}
		"""

rule rename_contigs:
	"""
	Edit contig headers so each sample has unique contig names with BBTools rename.sh.
	Prevents flye from crashing.
	"""
	input:
		os.path.join("results", "metaSPAdes", "{sample}", "contigs.fasta")
	output:
		os.path.join("results", "renamed_contigs", "{sample}_contigs.fasta")
	shell:
		"""
		ml {BBTOOLS}
		rename.sh \
			in={input} \
			out={output} \
			prefix={wildcards.sample} \
			addprefix=t
		"""

rule filter_contigs:
	"""
	Filter megahit-assembled contigs to a minimum of 1kb with Seqkit
	"""
	input:
		os.path.join("results", "renamed_contigs", "{sample}_contigs.fasta")
	output:
		os.path.join("results", "filtered_contigs", "{sample}_contigs_1kb.fasta")
	shell:
		"""
		ml {SEQKIT}
		seqkit \
			seq {input} \
			-m 1000 \
			-o {output}
		"""

rule concatenate_renamed_contigs:
        """
        Concatenate all individual (renamed) contig assemblies into one file for flye.
        Hopefully this prevents issues with samples producing 0 contigs.
        """
        input:
                expand(os.path.join("results", "filtered_contigs", "{sample}_contigs_1kb.fasta"), sample = SAMPLES)
        output:
                os.path.join("results", "concatenated_contigs", "concatenated_contigs_1kb.fasta")
	shell:
		"cat {input} > {output}"

rule assemble_contig_dictionary:
	"""
	Generate contig dictionary with Flye
	"""
	input:
		os.path.join("results", "concatenated_contigs", "concatenated_contigs_1kb.fasta")
	params:
		directory(os.path.join("results", "contig_dictionary"))
	output:
		os.path.join("results", "contig_dictionary", "assembly.fasta")
	threads: 8
	shell:
		"""
		ml {FLYE}
		flye \
			--subassemblies {input} \
			-o {params} \
			-t {threads} \
			--meta
		"""

rule filter_contig_dictionary:
	"""
	Filter the contigs in the contig dictionary to a minimum of 1kb with Seqkit.
	I'm not sure how it's possible for flye to generate contigs < 1kb considering
	I only gave it files of 1kb contigs but that's what seems to be happening anyway...
	"""
	input:
		os.path.join("results", "contig_dictionary", "assembly.fasta")
	output:
		os.path.join("results", "contig_dictionary", "assembly_1kb.fasta")
	shell:
                """
                ml {SEQKIT}
                seqkit \
                        seq {input} \
                        -m 1000 \
                        -o {output}
                """

rule build_reference_from_contig_dictionary:
	"""
	Build reference from contig dictionary for BBMap for the quantification by mapping (RPKM step)
	"""
	input:
		os.path.join("results", "contig_dictionary", "assembly_1kb.fasta")
	output:
		os.path.join("results", "ref", "genome", "1", "summary.txt")
	shell:
		"""
		ml {BBTOOLS}
		bbmap.sh \
			ref={input} \
			build=1 \
			path=./results
		"""
	
rule quantification_by_mapping:
	"""
	Map QC'd reads to contig dictionary with BBMap
	"""
	input:
		r1 = os.path.join(HECATOMB_DIR, "results", "QC", "step_7", "{sample}_R1.s7.out.fastq"),
                r2 = os.path.join(HECATOMB_DIR, "results", "QC", "step_7", "{sample}_R2.s7.out.fastq"),
		summary = os.path.join("results", "ref", "genome", "1", "summary.txt")
	output:
		sam = os.path.join("results", "quantification", "{sample}.aln.sam.gz"),
		rpkm = os.path.join("results", "quantification", "{sample}.rpkm"),
		covstats = os.path.join("results", "quantification", "{sample}.covstats")
	threads: 8
	shell:
		"""
		ml {BBTOOLS}	
		bbmap.sh \
			path=./results \
			build=1 \
			in={input.r1} \
			in2={input.r2} \
			out={output.sam} \
			rpkm={output.rpkm} \
			covstats={output.covstats} \
			kfilter=22 \
			subfilter=15 \
			maxindel=80 \
			ambiguous=random \
			physcov=t \
			t={threads}
		"""

rule generate_contig_abundances:
	"""
	Calculate contig abundances using TPM
	"""
	input:
		rpkm = expand(os.path.join("results", "quantification", "{sample}.rpkm"), sample = SAMPLES),
		covstats = expand(os.path.join("results", "quantification", "{sample}.covstats"), sample = SAMPLES)
	output:
		os.path.join("results", "contig_abundance_table", "contig_abundance_table.txt")
	shell:
		"""
		ml {R}
		Rscript ./workflow/scripts/Generate_Contig_Abundance_Table.R
		"""

rule build_reference_from_GVD:
	"""
	Build bbmap reference from the Human Gut Virome Database for contig dictionary annotation.
	"""
	input:
		{GVD}
	output:
		os.path.join("results", "ref", "genome", "2", "summary.txt")
	shell:
		"""
		ml {BBTOOLS}
		bbmap.sh \
			ref={input} \
			build=2 \
			path=./results
		"""

rule build_GVD_blast_db:
	"""
	Generate a nucleotide blastDB from the GVD file.
	"""
	input:
		{GVD}
	params:
		prefix = "GVD",
		out_dir = os.path.join("results", "GVD_blastN_db")
	output:
		os.path.join("results", "GVD_blastN_db", "GVD.ndb")
	shell:
		"""
		{BLAST}/makeblastdb \
			-in {input} \
			-out {params.prefix} \
			-dbtype nucl

		mv GVD.* {params.out_dir}
		"""

rule query_GVD:
	"""
	Run blastN search of filtered contig dictionary against GVD to get annotations.
	"""
	input:
		dbFile = os.path.join("results", "GVD_blastN_db", "GVD.ndb"),
		query = os.path.join("results", "contig_dictionary", "assembly_1kb.fasta")
	params:
		blast_dir = os.path.join("results", "GVD_blastN_db"),
		prefix = "GVD"
	output:
		os.path.join("results", "GVD_blastN_results", "GVD_contig_dictionary_blastN_results.tab")
	threads: 8
	shell:
		"""
		{BLAST}/blastn \
			-db {params.blast_dir}/{params.prefix} \
			-query {input.query} \
			-out {output} \
			-outfmt "6 qseqid sseqid pident length evalue bitscore" \
			-num_threads {threads}
		"""

rule build_GPD_blast_db:
	"""
	Generate a nucleotide blastDB from the Gut Phage Database file.
	"""
	input:
		{GPD}
	params:
		prefix = "GPD",
		out_dir = os.path.join("results", "GPD_blastN_db")
	output:
		os.path.join("results", "GPD_blastN_db", "GPD.ndb")
	shell:
		"""
		{BLAST}/makeblastdb \
			-in {input} \
			-out {params.prefix} \
			-dbtype nucl
		
		mv GPD.* {params.out_dir}
		"""

rule query_GPD:
	"""
	Run blastN search of filtered contig dictionary against GPD to get annotations.
	"""
	input:
		dbFile = os.path.join("results", "GPD_blastN_db", "GPD.ndb"),
		query = os.path.join("results", "contig_dictionary", "assembly_1kb.fasta")
	params:
		blast_dir = os.path.join("results", "GPD_blastN_db"),
		prefix = "GPD"
	output:
		os.path.join("results", "GPD_blastN_results", "GPD_contig_dictionary_blastN_results.tab")
	threads: 8
	shell:
		"""
		{BLAST}/blastn \
			-db {params.blast_dir}/{params.prefix} \
			-query {input.query} \
			-out {output} \
			-outfmt "6 qseqid sseqid pident length evalue bitscore" \
			-num_threads {threads}
		"""
